{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfcf740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.12\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2031c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa18a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/revanth/code/ai-engineering/llm_engineering/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5675d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1dbd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Hello, GPT! This is my first ever message to you! Hi!'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb681ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! Nice to meet you. Welcome to ChatGPT.\\n\\nI‚Äôm here to help with lots of things‚Äîquestions, explanations, writing, coding, planning, brainstorming, and more. Some quick ideas:\\n- Explain a concept in simple terms\\n- Draft an email or message\\n- Help with homework or studying\\n- Write a story, poem, or joke\\n- Debug or review code\\n- Plan a trip or a project\\n- Generate ideas or outlines\\n- Translate or summarize text\\n\\nWhat would you like to do today? If you‚Äôre not sure, tell me your interests and I‚Äôll tailor something for you.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337e7a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revanth - Cloud & Data Engineer | AWS Certified Professional\n",
      "\n",
      "Revanth.io\n",
      "Home\n",
      "About\n",
      "Skills\n",
      "Projects\n",
      "Contact\n",
      "Hi, I'm Revanth\n",
      "Data | Cloud | DevOps\n",
      "AWS Certified\n",
      "AWS Certifications\n",
      "AWS Cloud Practitioner\n",
      "AWS AI Practitioner\n",
      "AWS Data Engineer Associate\n",
      "AWS Solutions Architect Associate\n",
      "Data Pipeline Expert\n",
      "Infrastructure as Code\n",
      "Big Data Solutions\n",
      "View My Work\n",
      "Get In Touch\n",
      "About Me\n",
      "I'm a passionate Cloud and Data Engineer with 7+ years of expertise in building scalable infrastructure and data solutions that drive business value. With a strong foundation in AWS services, DevOps practices, and modern engineering tools, I help organizations architect robust, efficient systems that transform data into actionable insights.\n",
      "My experience spans across designing cloud-native architectures, implementing automated CI/CD workflows, building high-performance data pipelines, and optimizing infrastructure for scale. Whether it's architecting multi-cloud solutions, orchestrating containerized applications, or processing petabytes of data, I thrive on solving complex technical challenges and delivering reliable, cost-effective solutions.\n",
      "Technical Skills\n",
      "üîß Data Engineering\n",
      "Apache Spark\n",
      "Apache Kafka\n",
      "Apache Airflow\n",
      "dbt\n",
      "Databricks\n",
      "Snowflake\n",
      "ETL/ELT Pipelines\n",
      "Data Warehousing\n",
      "Data Lake Architecture\n",
      "‚òÅÔ∏è AWS Services\n",
      "EC2 & Lambda\n",
      "S3 & Glacier\n",
      "EMR\n",
      "Glue & Athena\n",
      "Kinesis\n",
      "Redshift\n",
      "RDS & DynamoDB\n",
      "CloudFormation\n",
      "Step Functions\n",
      "üöÄ DevOps & Tools\n",
      "Docker\n",
      "Kubernetes\n",
      "Terraform\n",
      "Jenkins\n",
      "GitLab CI/CD\n",
      "GitHub Actions\n",
      "Ansible\n",
      "Prometheus\n",
      "Grafana\n",
      "üíª Programming\n",
      "Python\n",
      "SQL\n",
      "Scala\n",
      "Shell Scripting\n",
      "PySpark\n",
      "Pandas\n",
      "NumPy\n",
      "Git\n",
      "Featured Projects\n",
      "Real-Time Data Pipeline\n",
      "Built a scalable real-time data pipeline processing 10M+ events daily using Kafka, \n",
      "                            Spark Streaming, and AWS services. Implemented exactly-once processing semantics \n",
      "                            and achieved sub-second latency.\n",
      "Apache Kafka\n",
      "Spark Streaming\n",
      "AWS Kinesis\n",
      "Python\n",
      "Data Lake Architecture\n",
      "Designed and implemented a cloud-\n"
     ]
    }
   ],
   "source": [
    "# Utility\n",
    "rev = fetch_website_contents(\"https://revanth.io\")\n",
    "print(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9c06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
